**ðŸ”Ž Step 1: Open the Experiment**

On the left sidebar youâ€™ll see Experiments.

You should see one called amazon_delivery_time (this is the one created in your training script).

Click on it â†’ this opens the experiment dashboard.

**ðŸ”Ž Step 2: Explore Runs**

Each time you trained a model (Random Forest, XGBoost, etc.), MLflow created a Run entry.

For each run, youâ€™ll see:

run_name â†’ e.g., random_forest, xgboost

rmse â†’ root mean squared error

mae â†’ mean absolute error

r2 â†’ coefficient of determination

params â†’ model hyperparameters (like n_estimators)

âœ… Compare them side by side â€” youâ€™ll notice your random_forest run has the lowest RMSE.

**ðŸ”Ž Step 3: Drill Down Into a Run**

Click on the run_id (blue link). Inside youâ€™ll find:

Parameters: model settings used.

Metrics: graphs of RMSE, MAE, RÂ².

Artifacts: saved model, preprocessing pipeline, etc.

Tags: metadata about the run.